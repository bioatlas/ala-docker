######################################################################
#
# Biocache configuration file
#
# This file has been generated via an ansible script.
#
######################################################################

# The email address of the technical contact
technical.contact=support@biodiversitydata.se

# Whether to enable performance analysis using JMX
jmx.debug.enabled=true

# The base URL for biocache web services
webservices.root=https://records.biodiversitydata.se/ws

# Cassandra Config
db=cassandra3
# cassandra hosts - this should be comma separated list in the case of a cluster
cassandra.hosts=cassandra-1,cassandra-2,cassandra-3,cassandra-4
cassandra.port=9042
#local.node.ip=127.0.0.1
cassandra.pool=biocache-store-pool
cassandra.keyspace=occ
cassandra.max.connections=-1
cassandra.max.retries=6
thrift.operation.timeout=80000
cluster.size=4
node.number=0
cassandra.async.updates.enabled = false
cassandra.async.updates.threads = 1
cassandra.async.paging.enabled = false
cassandra.token.split = 10

# The number of concurrent Cassandra update threads
cassandra.update.threads= 1

# Record page size used by processing, indexing and other operations using a full table scan
cassandra.fetch.size= 500

# Database read timeout in milliseconds
cassandra.timeout= 120000

# Zookeeper address - used to retrieve SOLR configuration if not available locally
zookeeper.address = zookeeper1,zookeeper2
zookeeper.updates.enabled = false
#######################################################
# File system usage
#######################################################

# Directory used to track the status of uploads
upload.status=/data/biocache-upload/status

# Directory used by sandbox functionality to write data files to be ingested
upload.temp=/data/biocache-upload/temp

# Base URL to media files
media.url=https://records.biodiversitydata.se/ws/biocache-media/

# Directory root for images
media.dir=/data/biocache-media/

# The type of media store (none, local, remote or auto)
media.store.local=false
media.store.type=auto

# URL instance of image-service to store media
media.store.url=https://images.biodiversitydata.se
media.store.connection.pool.size=25
media.store.connection.pool.maxperroute=25
media.store.maxrequests.persec=10
#API key for imageservice
imageservice.api.key=3cdad681-2fa4-47a1-a8d2-6ea789cf003f

# Directory to log deleted row keys to
deleted.file.store=/data/biocache-delete/

# List tool endpoint
list.tool.url=https://lists.biodiversitydata.se

# Whether to enable list tool integration (this is used at indexing time only)
include.species.lists=true

# Whether or not to enable SDS checks
sds.enabled=false

# SDS data file
sds.url=https://sds.biodiversitydata.se
sds.species.data=https://sds.biodiversitydata.se/sensitive-species-data.xml
sds.category.data=https://sds.biodiversitydata.se/sensitivity-categories.xml
sds.zone.data=https://sds.biodiversitydata.se/sensitivity-zones.xml
sds.spatial.layers=cl10038

# The directory to write files to while ingesting data
load.dir=/data/biocache-load/

# Charts services
charts.facets.string.max= 1000
charts.facets.number.max= 1000

#######################################################
# External services
#######################################################

# The URL of SOLR services. In the case of embedded SOLR (no for production), this could be a directory path instead
# solrHome=http://localhost:8080/solr
# OR a list of Zookeeper nodes if the Solr configuration is stored in Zookeeper (advertised on port 2181)
solr.home=zookeeper1:2181,zookeeper2:2181
#solr.home=http://solr:8983/solr/biocache

# Solr HTTP Client Connection Pool configuration to avoid opening too many concurrent connections to the Solr server
solr.connection.pool.size= 50
solr.connection.pool.maxperroute= 50

# Solr HTTP Connection timeout defaults, in milliseconds (could have been overriden in internal Solr Client code in various places)
solr.connection.connecttimeout= 30000
solr.connection.requesttimeout= 30000
solr.connection.sockettimeout= 30000

# Solr HTTP Cache settings (requires you to setup HTTP Cache headers in your solr configuration before they will take effect)
solr.connection.cache.entries= 500
# Maximum object size to store in the cache, in bytes (Default 256 kilobytes: 1024 * 256 = 262144 bytes)
solr.connection.cache.object.size= 262144

# The number of concurrent Solr update threads
solr.update.threads=4

# The HTTP User Agent used for some queries from biocache-store
biocache.useragent=Biocache

# The SOLR collection to query
solr.collection=biocache

# Base URL for registry (collectory) web services
registry.url=https://collections.biodiversitydata.se/ws

# URL to use for retrieve a citations CSV for downloads
citations.url=https://collections.biodiversitydata.se/ws/citations

# API key to use to authenticate WS requests
registry.api.key=7cde19e0-58f4-4c3d-9205-1c4b0d2e5b1f

# If enabled, processing & loading operations will cause an metadata update in the registry
allow.registry.updates=false

# Base URL for taxon services (BIE)
service.bie.ws.url=https://species.biodiversitydata.se/ws

# Base URL for taxon pages (BIE)
service.bie.ui.url=https://species.biodiversitydata.se

# Allow service to be disabled via config (enabled by default)
service.bie.enabled=false

# Base URL for Biocache UI
biocache.ui.url=https://records.biodiversitydata.se

# Base URL for DOI service DOI
doi.ui.url=https://doi.ala.org.au
doi.service.url=https://doi.ala.org.au/api/
doi.service.apiKey=
doi.service.readTimeout=900000
doi.provider=ALA

# A fixed period after minting a DOI to allow it to propagate
download.doi.propagation.delay=60000

#######################################################
# Miscellaneous configuration options
#######################################################

# The URL of layer services
layers.service.url=https://spatial.biodiversitydata.se/ws

# The URL of the spatial-service /fields service
spatial.layers.url=https://spatial.biodiversitydata.se/ws/fields

# To use layers service for sampling
layers.service.sampling=true

# Used by location processor for associating a country with an occurrence record where only stateProvince supplied and not coordinates are available
default.country=

# Specify fields to sample - set to 'none' for no sampling
sample.fields=

# The list of default fields to use if a list can not be obtained from the spatial layers.
default.sample.fields=
#defaultFieldsToSample=cl20,cl23,cl901,cl914,cl916,cl935,el594,el848,el815,el834,el707,el794,el786,el789,el774,el851,el647,el717,el708,el748,el821,el777,el832,el814,el823,el816,el712,el841,el845,el839,el844,el836,el817,el811,el855,el804,el899,el737,el756,el759,el752,el739,el776,el753,el716,el729,el751,el827,el673,el810,el820,el830,el779,el813,el598,el835,el808,el807,el715,el833,el837,el719,el809,el829,el838,el725,el765,el745,el822,el798,cl606,cl611,cl612,cl613,cl614,cl617,cl605,cl620,el727,el843,el760,el758,el842,el818,el714,el812,el840,el730,el722,el866,el773,el876,el871,el872,el886,el887,el894,el877,el874,el862,el875,el883,el892,el879,el889,el881,el880,el890,el882,el864,el885,el868,el891,el724,el873,el884,el865,el895,el878,el863,el867,el870,el858,el850,el860,el768,el854,el857,el859,el849,el757,el755,el682,el681,el733,el856,el720,el732,el761,el721,el762,el772,el668,el746,el731,el671,el728,el743,el749,el744,el734,el750,el600,el726,el718,el736,el713,el602,el593,el771,el601,el764,el778,el595,el888,el596,el599,el723,el788,el791,el782,el806,el742,el797,el893,el735,el754,el766,el740,el775,el763,el853,el796,el869,el861,el675,el793,el787,el781,el795,el785,el852,el670,el799,el790,el783,el704,el666,el672,el591,el802,el800,el803,el801,el805,el661,el738,el705,el792,el784,el667,cl917,cl925,cl926,el676,el597,el680,el674,el747,el711,el828,el770,el819,el898,el706,el767,cl928,cl929,cl930,cl900,el769,el741,cl902,cl903,cl904,cl905,cl906,cl907,cl908,cl909,cl910,cl932,cl923,cl911,cl912,cl678,el831,el669,el825,el826,el662,el709,cl618,cl896,cl604,cl619,cl922,el824,cl927,cl913,cl942,cl21,cl22

# geospatial layers used to add darwin core properties from lat/lng. uses IDs of layers from layer service
layer.state.province=cl10097
layer.terrestrial=
layer.marine=
layer.countries=cl10087
layer.localgov=

# Lucene indexes for name matching
name.index.dir=/data/lucene/namematching

# The languages to use for common names. Applicable for people using GBIF name matching indexes
commonname.lang=sv,en

# Exclude sensitive values for the listed data resources (comma separated list)
exclude.sensitive.values=

# Additional fields to index (used by biocache-store only)
extra.misc.fields=
#extraMiscFields=OriginalSeedQuantity_i,AdjustedSeedQuantity_i,CurrentSeedQuantity_i,ViabilitySummary_d

additional.fields.to.index=materialSampleID,sampleSizeUnit,sampleSizeValue,organismQuantity,organismQuantityType

# Max number of threads to use when processing an endemic request
endemic.query.maxthreads= 30

# Max number of threads to use when processing a solr search query which is not an endemic query, or an online download or an offline download
solr.downloadquery.maxthreads=30

# Max number of threads to use when processing an online download (occurrences/index/download)
online.downloadquery.maxthreads=30

# Max number of threads to use when processing an offline download (occurrences/offline/download)
download.offline.parallelquery.maxthreads= 30

# An artificial throttle used between calls to Solr for paged results, including online and offline downloads
download.throttle.ms=50

# The batch size for individual queries to Solr during downloads
download.batch.size=500

# The size of an internal fixed length blocking queue used to parallelise reading from Solr before writing to this queue
download.internal.queue.size=100

# Maximum total time for downloads to be execute. Defaults to 1 week (604,800,000ms)
download.max.execute.time=604800000

# Maximum total time to wait for downloads to be written to disk after Solr queries are complete. Defaults to 5 minutes (300,000ms)
# Increase this if you are seeing messages about downloads being interrupted
# This needs to be fairly large as shapefiles are completely written to temp files after all of the Solr queries complete
download.max.completion.time= 300000

# The fixed page size used by the biocache-service scatterplot service when querying solr
scatterplot.query.page.size=100000

# The fixed page size used by the biocache-service WMS tiles server when querying solr if uncertainty circles are required
wms.pagesize=100000

# Base directory for heatmap images
heatmap.output.dir=/data/output/heatmap

# AuthService properties to inject
auth.user.details.url=https://auth.biodiversitydata.se/userdetails/userDetails/
auth.user.names.id.path=getUserList
auth.usernames.for.numeric.id.path=getUserListWithIds
auth.substitution.fields=assertion_user_id,user_id,alau_user_id

# Enable and customise this to check API keys
apikey.check.enabled=true
apikey.check.url=https://auth.biodiversitydata.se/apikey/ws/check?apikey={0}

# Caches to enable/disable. Comment out the caches that you wish to enable
caches.auth.enabled=true
caches.log.enabled=true

# Note: The collections cache is problematic when collectory/biocache-service on deployed on the same tomcat
caches.collections.enabled=true
caches.layers.enabled=true

taxon.profile.cache.all=true

# Cache sizes can be lowered to reduce memory footprint at the possible cost of throughput
taxon.profile.cache.size=10000
classification.cache.size=10000
commonname.cache.size=10000
spatial.cache.size=10000
attribution.cache.size=10000
sensitivity.cache.size=10000
location.cache.size=10000

# Citations disable - for now we can disable them in the future will need a way to customise the source.
citations.enabled=true

# URL for retrieve list of contacts for collection
collection.contacts.url=https://collections.biodiversitydata.se/ws/collection

# URL for LoggerService
logger.service.url=https://logger.biodiversitydata.se/service/logger
occurrence.log.enabled=true

# Temporary working directory (used by processing)
tmp.work.dir=/data/tmp

# Restart Data Service
# Warning: Uses unsynchronised reflection to access private fields and save/restore them from disk
# Enable at your own risk
restart.data.enabled=false
restart.data.frequency=60000

#######################################################
# Volunteer portal (DigiVol) integration
#######################################################

# Hub ID for the DigiVol
volunteer.hub.uid=
# Data Provider ID for DigiVol
volunteer.dp.uid=

#######################################################
# SFTP integration
#######################################################

# User details to SFTP/SCP from upload
uploadUser=
uploadPassword=


#######################################################
# Facets
#######################################################

# Limit to &facets term count for all queries
facets.max=32

# Limit the default &facets term count. This limits the default facets assigned from facets.json
facets.defaultmax=0

# Default &facet value (true|false). Clients must always set &facet=true when facets are required and this default is false.
facet.default=true

# Autocomplete related caches, it will still work when these are disabled but the cached information will be unavailable.
autocomplete.species.images.enabled=true
autocomplete.species.counts.enabled=true
autocomplete.commonnames.extra.enabled=true

# species.counts.async.updates is only used when autocomplete.species.counts.enabled=true
# When true the autocomplete will return without waiting for species counts to be populated or updated.
species.counts.async.updates=true

# species.counts.cache.minage is only used when autocomplete.species.counts.enabled=true
# Each species counts cache is updated at the first use, after a change to the index, and when the last update is older
# than this time in ms. The default is no more than 1 update every 30 minutes for each species counts cache.
species.counts.cache.minage=1800000

# Set SOLR batch size. Default=1000
solr.batch.size=500

# Set SOLR hard commit size. Default=10000 - used in indexing.
solr.hardcommit.size=5000

# Temporary directory where shapefiles are created for downloads
shapefile.tmp.dir=/data/biocache-download/tmp

# URL or path to subgroups JSON configuration
species.subgroups.url=/data/biocache/config/subgroups.json

#######################################################
# Downloads
#######################################################

# offline downloads email
download.email.subject=[hubName] Occurrence Download Complete - [filename]
download.date.format=dd MMMMM yyyy
download.auth.sensitive=false
download.solr.only=true

download.email.template=/data/biocache/config/download-email.html
download.readme.enabled=true
download.readme.template=/data/biocache/config/download-readme.html

download.doi.licence.prefix=Datasets are covered by the following licence(s):
download.doi.title.prefix=Occurrence download
download.doi.landing.page.baseUrl=https://records.biodiversitydata.se/download/doi?doi=
download.doi.resolver=https://doi.ala.org.au/doi/

download.support.email.enabled=false
download.support.email=support@biodiversitydata.se
download.support=support@biodiversitydata.se
my.download.doi.baseUrl=
#https://doi.ala.org.au/myDownloads

download.doi.failure.message=A DOI was requested for this download however it could not be minted.

download.doi.email.template=/data/biocache/config/download-doi-email.html
download.doi.readme.template=/data/biocache/config/download-doi-readme.html

download.csdm.email.template=/data/biocache/config/download-csdm-email.html
download.email.subject=SBDI Occurrence Download Complete - [filename]

email.sender=download@biodiversitydata.se
mail.smtp.host=postfix
mail.smtp.port=25

#DOI Default metadata
doi.author=SBDI
doi.description=SBDI record download
doi.resourceText=Species information

# Base URL for generated download files
download.url=https://records.biodiversitydata.se/ws/biocache-download
download.dir=/data/biocache-download

# Download queue configuration
concurrent.downloads.json=[{"label": "smallSolr", "threads": 4, "maxRecords": 50000, "type": "index", "pollDelay": 10, "executionDelay": 10, "threadPriority": 5}, {"label": "largeSolr", "threads": 1, "maxRecords": 100000000, "type": "index", "pollDelay": 100, "executionDelay": 100, "threadPriority": 1}, {"label": "smallCassandra", "threads": 1, "maxRecords": 50000, "type": "db", "pollDelay": 10, "executionDelay": 10, "threadPriority": 5}, {"label": "defaultUnrestricted", "threads": 1, "pollDelay": 1000, "executionDelay": 100, "threadPriority": 1}]

# Maximum points in WKT string supported before simplification applies
# Set this to 0 to disable simplification (disabling not recommended due to performance issues)
qid.wkt.maxPoints=50000

# The step size factor during the iteration simplification algorithm
qid.wkt.simplification.factor=2.0

# The initial precision to attempt during simplification
qid.wkt.simplification.initialprecision=0.0001

# The maximum precision to attempt during simplification before giving up
qid.wkt.simplification.maxprecision=10.0

# Maximum size of the WMS cache
wms.cache.size.max=104857600

# Default set of fields in the download - for the legacy format
#default.download.fields=id,data_resource_uid,data_resource,institution_uid,institution_name,collection_uid,collection_name,license,catalogue_number,taxon_concept_lsid,raw_taxon_name,raw_common_name,taxon_name,rank,common_name,kingdom,phylum,class,order,family,genus,species,subspecies,institution_code,collection_code,locality,raw_latitude,raw_longitude,raw_datum,latitude,longitude,coordinate_precision,coordinate_uncertainty,country,state,cl959,min_elevation_d,max_elevation_d,min_depth_d,max_depth_d,individual_count,recorded_by,year,month,day,verbatim_event_date,basis_of_record,raw_basis_of_record,occurrence_status,sex,preparations,information_withheld,data_generalizations,outlier_layer,taxonomic_kosher,geospatial_kosher,materialSampleID,sampleSizeUnit,sampleSizeValue,organismQuantity,organismQuantityType
downloads.dwcExtraFields=data_resource_uid,materialSampleID,sampleSizeUnit,sampleSizeValue,organismQuantity,organismQuantityType

# Maximum offline file size
download.offline.max.size=50000000

# Shapefile downloads enabled
download.shp.enabled=true

# Grid indexing enabled (used by biocache store only)
gridref.indexing.enabled=true

# National checklist GUID pattern
national.checklist.guid.pattern=.*

# Used in OGC XML services
organizationName=
orgCity=
orgStateProvince=
orgPostcode=
orgCountry=
orgPhone=
orgFax=
orgEmail=

geoserver.url=https://spatial.biodiversitydata.se/geoserver

# Used when creating new layer fields (el or cl) in the live SOLR instance
solr.index.docvalues.layer=false
solr.index.indexed.layer=true
solr.index.stored.layer=true

# Used when creating new misc fields in the live SOLR instance
solr.index.docvalues.misc=false
solr.index.misc=true
solr.index.stored.misc=true

# Where to get the IRMNG data from
irmng.archive.url=https://archives.ala.org.au/archives/nameindexes/irmng/IRMNG_DWC.zip

dataquality.baseUrl=https://dataquality.ala.org.au/
dataquality.enabled=false
dataquality.apiKey=

download.auth.bypass=true
download.auth.role=ROLE_USER
downloads.gaCustomData=
